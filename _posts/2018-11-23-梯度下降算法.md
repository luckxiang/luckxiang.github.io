---
layout: post
title: 梯度下降算法
date: 2018-11-23
categories: blog
tags: [算法]
description: 
---

前几天有个朋友,说他在搞梯度下降算法,让我一起帮忙看看这个东西到底怎么回事.具体算法我没有去深入分析,只是从宏观上去理解了一下,先在二维平面上感受一下:
<center>
<p><img src="https://i.loli.net/2018/11/23/5bf76d0425915.jpg" align="center"></p>
</center>

我们从圆环的最外边的某一个点开始,往圆环中心走,不管怎么样,我们都能到达圆环中心,现在问题来了,假设我们可以瞬间出现在同一个圆环的任意一点,怎么走可以最快到达中心,是不是只要找到相邻圆环最近的点就可以了.这个就是迭代优化算法的核心了:对一个收敛的函数,通过迭代算法,怎么才能最快的一步一步逼近我们想要的极值.当然最快只是我们的追求,梯度算法就是我们实现这个追求的途径.在梯度算法中,我们设置一个迭代的步长(深度学习里边叫学习速率),然后沿着目标变化最快的方向逼近,(如果是梯度下降,就沿着下降最快的方向逼近,如果是梯度上升,就沿着数值上升最快的方向逼近).直到变化速率达到我们设定的目标值.这个时候极值也就出来了.         
在这个模型中,显然有两个问题,一个是步长大小怎么定,从这个角度出发可以得到很多优化算法.如冲量梯度下降.还有一个问题是假如函数非常复杂,可能存在很多的极值,我们求出的极值不一定是最合理的极值.例如下图:
<center>
<p><img src="https://i.loli.net/2018/11/23/5bf76d281820f.jpg" align="center"></p>
</center>
这个图里边就有两个波峰,两个波谷.我们求解的结果不一定是想要的,从这个角度出发,又可以得到一些优化算法.这两个思考方向应该就是梯度算法里边最核心的问题了,需要根据自己遇到的实际问题去设计最优的算法.       
over
